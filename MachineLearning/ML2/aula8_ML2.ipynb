{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo aula 8 de Machine Learning 2 ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clusterização Hierárquica\n",
    "\n",
    "O método de clusterização hierárquica realiza a identificação dos agrupamentos nos dados de forma hierárquica, encontrando grupos dentro de grupos de uma forma hierarquizada. Esse tipo de técnica de agrupamento é muito utilizada e parecida com classificações taxonômicas de espécies animais ou vegetais. O agrupamento, portanto, é feito de uma forma que parece uma árvore de decisão, onde o nó raiz corresponde a todos os dados (agrupamento total) e cada divisão vai gerando os clusters.\n",
    "\n",
    "<img src=\"https://th.bing.com/th/id/R.df228cb781b9fc1f7bb98596396122be?rik=C2mrkHa9pmyM9A&riu=http%3a%2f%2fwww.statisticshowto.com%2fwp-content%2fuploads%2f2016%2f11%2fclustergram.png&ehk=b6Khl19cSqpqMrZKlr3zpc5KM8XsyCgUrnGJ40NNRLY%3d&risl=&pid=ImgRaw&r=0&sres=1&sresct=1\" width=\"700px\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A divisão dos agrupamentos pode ser realizada, essencialmente de duas formas:\n",
    "\n",
    "- **Agrupamento Divisivo** ou *Top-Down*: inicialmente os dados são atribuídos a um único cluster, e depois, vão sendo sequencialmente divididos até que cada observação seja um cluster\n",
    "- **Agrupamento Aglomerativo** ou *Bottom-Up*: inicialmente, cada dado é considerado um cluster. Sequencialmente, os clusters vão sendo agrupados até que todos os dados estejam agrupados num único cluster.\n",
    "\n",
    "Ou seja, os algoritmos são exatamente o oposto um do outro, de forma que vamos entender o algoritmo de Clusterização Aglomerativa.\n",
    "\n",
    "### Como a Clusterização Aglomerativa funciona?\n",
    "\n",
    "- 1. Inicia-se assinalando cada observação como um *cluster de único ponto*. (N clusters)\n",
    "- 2. Encontrar o par de cluster (pontos) mais próximo (maior similaridade) e colocá-los num único cluster (N-1 clusters)\n",
    "- 3. Encontrar o par de clusters (grupos de pontos) mais próximo e colocá-los num único cluster (N-2 clusters)\n",
    "- 4. Repetir 2 e 3 até que todos os pontos do dataset estejam agrupados.\n",
    "\n",
    "No `scikit-learn`, a classe usada é o `AgglomerativeClustering`, cuja documentação pode ser encontrada [aqui](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html) e [aqui](https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beleza, mas como posso comparar clusters quanto à sua similaridade?\n",
    "\n",
    "Bom, essa pergunta é fácil. Existem diversas formas de se calcular a similaridade de dois objetos multidimensionais. As principais e mais conhecidas:\n",
    "\n",
    "- distância Euclidiana\n",
    "\n",
    "$$d_E = \\sqrt{\\sum_{i=1}^N (x_{1,i} - x_{2,i})^2}$$\n",
    "\n",
    "- distância Manhattan\n",
    "\n",
    "$$d_M = \\sum_{i=1}^N |x_{1,i} - x_{2,i}|$$\n",
    "\n",
    "- distância de Minkowski\n",
    "\n",
    "$$d_{Mp} = \\Bigg(\\sum_{i=1}^n |x_{1,i} - x_{2,i}|^p\\Bigg)^{1/p}$$\n",
    "\n",
    "### Mas e para determinar quais são os clusters que devem ser unidos ou não?\n",
    "\n",
    "Nesse caso, devemos usar técnicas de ligação de clusters - *Linkage Algorithms*. A escolha do algoritmo de ligação de clusters é muito importante e pode determinar significativamente a qualidade da clusterização.\n",
    "Vamos ver alguns tipos de ligação.\n",
    "\n",
    "- **Ligação Simples** ou *Simple Linkage* - a distância entre os clusters é o mínimo das distâncias ou a distância entre os pontos mais próximos de cada cluster\n",
    "- **Ligação Completa** ou *Complete Linkage* - é a máxima distância entre os elementos do cluster\n",
    "- **Ligação Média** ou *Average Linkage* - É a distância média entre todos os pares de pontos de cada cluster\n",
    "- **Método do Centróide** - Mínima distância entre os centroides de cada cluster\n",
    "- **Método de Ward** - Combinação dos clusters de modo que o aumento de variância seja o menor possível, com o objetivo de minimizar o WCSS\n",
    "\n",
    "<img src=\"https://d1m75rqqgidzqn.cloudfront.net/wp-data/2020/07/01130934/june-30-hierarchical-clustering-infograph-for-blog-8.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vantagens e Desvantagens\n",
    "\n",
    "### **Vantagens**\n",
    "\n",
    "- não existem hipóteses sobre o formato dos clusters (KMeans, por exemplo, traça um \"círculo\" ao redor do centroide do cluster)\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*DVcjzP5yfsLRkuRGCZwmqQ.png\">\n",
    "\n",
    "- pode-se clusterizar o dataset em diferentes níveis de granularidade com uma única execução (KMeans, GMM e DBSCAN tem parâmetros tunáveis)\n",
    "- no caso da utilização de distâncias conhecidas, o resultado torna-se mais fácil de interpretar\n",
    "\n",
    "### **Desvantagens**\n",
    "\n",
    "- muitas vezes a tomada de decisão é baseada em heurística, o que torna o algoritmo muito dependente da aplicação especialista de conhecimento de negócio\n",
    "- é matematicamente custoso devido aos repetidos cálculos de distâncias entre os pontos\n",
    "- dendogramas funcionam apenas com poucas quantidades de amostras. Em casos mais reais, os dendogramas tornam-se muito difíceis de ler e interpretar\n",
    "\n",
    "<img src=\"https://th.bing.com/th/id/OIP.GtLjRzpWBLNaIYZfCOKL-QHaHL?pid=ImgDet&rs=1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
